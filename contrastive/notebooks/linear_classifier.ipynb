{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch-lightning.readthedocs.io/en/stable/starter/introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve,\\\n",
    "roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, latent_space_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, latent_space_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(latent_space_dim, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.encoder(x)\n",
    "        output = self.decoder(embedding)\n",
    "        return output\n",
    "\n",
    "    def forward_embedding(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "# init model\n",
    "latent_space_dim = 15\n",
    "autoencoder = LitAutoEncoder(latent_space_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/2022_jchavas_cingulate_inhibitory_control/venv_local/lib/python3.6/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 51.2 K\n",
      "1 | decoder | Sequential | 52.0 K\n",
      "---------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.413     Total estimated model params size (MB)\n",
      "/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/2022_jchavas_cingulate_inhibitory_control/venv_local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15af17d36e8140b389b4fd55e4f66380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "# most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
    "# trainer = pl.Trainer(accelerator=\"gpu\", devices=8) (if you have GPUs)\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_X_y_loader = DataLoader(dataset, batch_size=60000)\n",
    "\n",
    "X,Y = list(get_X_y_loader)[0]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 230\n",
    "\n",
    "outputs = autoencoder.forward(X[i].flatten())\n",
    "outputs = outputs.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f42eae4a630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X[i][0])\n",
    "plt.figure()\n",
    "plt.matshow(outputs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1451,  0.4071, -0.1414, -0.5115, -0.3112,  0.1048, -0.6085,  1.0817,\n",
       "          0.4114,  0.2532,  1.3883, -1.2937, -0.9001,  0.4669, -0.6296],\n",
       "        [-0.3082,  0.1954,  1.4195, -1.6393, -0.5129,  0.4608, -0.4463, -0.0473,\n",
       "         -1.6607, -0.0989,  2.1451, -2.1447, -0.2214, -0.3113, -1.0416],\n",
       "        [ 0.5421, -0.5779,  0.3321,  0.4336, -0.7860,  1.5834, -0.7857,  0.2791,\n",
       "         -0.6690,  0.4184,  1.0873,  0.8694,  0.2971,  0.4749, -0.4133],\n",
       "        [ 0.6593,  1.1012,  0.0329, -0.7978, -0.4490, -1.0858, -0.9697,  0.2747,\n",
       "         -0.3702,  1.0820, -0.7492, -0.6860,  0.7247,  0.7379, -0.0405],\n",
       "        [ 1.5528,  0.9656, -0.4108, -0.2011,  0.0325,  1.0843, -0.9245, -0.8705,\n",
       "          0.6207,  0.5341,  0.4353,  0.1880,  0.8525,  0.1990, -1.2704],\n",
       "        [-0.2546, -0.5055, -0.3217, -0.9141,  0.1953, -0.0766, -1.4160,  0.2664,\n",
       "         -0.5521,  0.5213,  2.4485, -0.5218,  0.7170,  0.7340, -0.2391],\n",
       "        [ 0.0423, -0.6327, -1.3651, -0.2742,  0.6104, -0.2256,  0.6618, -0.2678,\n",
       "          1.2627,  0.3030, -0.1669, -0.1621, -1.6048, -0.3674, -0.0601],\n",
       "        [-0.6200,  0.5272, -1.3328, -0.3953, -0.9206,  0.6206, -2.0795,  1.4320,\n",
       "         -0.8538,  0.4984,  1.6740, -0.3943, -0.2718, -0.0918, -0.8491],\n",
       "        [ 0.1292, -0.1000, -0.5018, -0.2043,  0.7514, -0.0133,  0.4659, -0.0435,\n",
       "          0.9219,  0.6064, -0.3290, -0.0505, -1.4308, -0.3684, -0.2941],\n",
       "        [-0.2633,  0.5828,  0.8022, -0.7769, -0.2222,  0.7274, -1.3411, -1.0687,\n",
       "         -0.6581,  1.3034,  0.6307,  0.4347,  0.1267,  0.7440, -0.6647]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.forward_embedding(X[:10].flatten(start_dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Linear(input_size, output_size)\n",
    "        self.activation0 = nn.Softmax(dim=1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        output = self.layer0(x)\n",
    "        output = self.activation0(output)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        output = self.forward(x)\n",
    "        loss = self.loss(output, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the linear classifier\n",
    "lin_class = LinearClassifier(latent_space_dim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1451,  0.4071, -0.1414, -0.5115, -0.3112,  0.1048, -0.6085,  1.0817,\n",
      "          0.4114,  0.2532,  1.3883, -1.2937, -0.9001,  0.4669, -0.6296],\n",
      "        [-0.3082,  0.1954,  1.4195, -1.6393, -0.5129,  0.4608, -0.4463, -0.0473,\n",
      "         -1.6607, -0.0989,  2.1451, -2.1447, -0.2214, -0.3113, -1.0416],\n",
      "        [ 0.5421, -0.5779,  0.3321,  0.4336, -0.7860,  1.5834, -0.7857,  0.2791,\n",
      "         -0.6690,  0.4184,  1.0873,  0.8694,  0.2971,  0.4749, -0.4133],\n",
      "        [ 0.6593,  1.1012,  0.0329, -0.7978, -0.4490, -1.0858, -0.9697,  0.2747,\n",
      "         -0.3702,  1.0820, -0.7492, -0.6860,  0.7247,  0.7379, -0.0405],\n",
      "        [ 1.5528,  0.9656, -0.4108, -0.2011,  0.0325,  1.0843, -0.9245, -0.8705,\n",
      "          0.6207,  0.5341,  0.4353,  0.1880,  0.8525,  0.1990, -1.2704],\n",
      "        [-0.2546, -0.5055, -0.3217, -0.9141,  0.1953, -0.0766, -1.4160,  0.2664,\n",
      "         -0.5521,  0.5213,  2.4485, -0.5218,  0.7170,  0.7340, -0.2391],\n",
      "        [ 0.0423, -0.6327, -1.3651, -0.2742,  0.6104, -0.2256,  0.6618, -0.2678,\n",
      "          1.2627,  0.3030, -0.1669, -0.1621, -1.6048, -0.3674, -0.0601],\n",
      "        [-0.6200,  0.5272, -1.3328, -0.3953, -0.9206,  0.6206, -2.0795,  1.4320,\n",
      "         -0.8538,  0.4984,  1.6740, -0.3943, -0.2718, -0.0918, -0.8491],\n",
      "        [ 0.1292, -0.1000, -0.5018, -0.2043,  0.7514, -0.0133,  0.4659, -0.0435,\n",
      "          0.9219,  0.6064, -0.3290, -0.0505, -1.4308, -0.3684, -0.2941],\n",
      "        [-0.2633,  0.5828,  0.8022, -0.7769, -0.2222,  0.7274, -1.3411, -1.0687,\n",
      "         -0.6581,  1.3034,  0.6307,  0.4347,  0.1267,  0.7440, -0.6647]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# create its dataset\n",
    "X_propag = X.flatten(start_dim=1)\n",
    "embeddings = autoencoder.forward_embedding(X_propag)\n",
    "embeddings.detach_()\n",
    "print(embeddings[:10])\n",
    "\n",
    "# apparently no need\n",
    "Y_one_hot = F.one_hot(Y).type(torch.FloatTensor)\n",
    "print(Y_one_hot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | layer0      | Linear           | 160   \n",
      "1 | activation0 | Softmax          | 0     \n",
      "2 | loss        | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "160       Trainable params\n",
      "0         Non-trainable params\n",
      "160       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e795774274e4347837a060cedc0ef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the linear classifier on the latent space embedding\n",
    "\n",
    "train_set = TensorDataset(embeddings, Y)\n",
    "train_loader_lin = DataLoader(train_set, batch_size=10)\n",
    "\n",
    "trainer_lin = pl.Trainer(max_epochs=5)\n",
    "trainer_lin.fit(model=lin_class, train_dataloaders=train_loader_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.009928e-03</td>\n",
       "      <td>7.469503e-06</td>\n",
       "      <td>1.242133e-02</td>\n",
       "      <td>5.613064e-01</td>\n",
       "      <td>1.004791e-07</td>\n",
       "      <td>0.396970</td>\n",
       "      <td>2.022694e-04</td>\n",
       "      <td>4.241157e-03</td>\n",
       "      <td>1.822945e-02</td>\n",
       "      <td>1.611490e-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.990822e-01</td>\n",
       "      <td>2.948407e-16</td>\n",
       "      <td>1.438319e-11</td>\n",
       "      <td>1.364113e-11</td>\n",
       "      <td>6.809391e-13</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>1.329700e-08</td>\n",
       "      <td>1.075142e-10</td>\n",
       "      <td>3.041454e-09</td>\n",
       "      <td>1.223539e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.984737e-05</td>\n",
       "      <td>4.445837e-11</td>\n",
       "      <td>1.486989e-06</td>\n",
       "      <td>3.889900e-04</td>\n",
       "      <td>6.483795e-01</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>4.275278e-06</td>\n",
       "      <td>1.129403e-03</td>\n",
       "      <td>2.429402e-05</td>\n",
       "      <td>3.495889e-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.455174e-07</td>\n",
       "      <td>9.844857e-01</td>\n",
       "      <td>9.453045e-04</td>\n",
       "      <td>7.356701e-06</td>\n",
       "      <td>7.178605e-06</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>3.769938e-05</td>\n",
       "      <td>4.704677e-05</td>\n",
       "      <td>1.431262e-02</td>\n",
       "      <td>6.472946e-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.702829e-09</td>\n",
       "      <td>1.626378e-07</td>\n",
       "      <td>1.095382e-10</td>\n",
       "      <td>8.777641e-10</td>\n",
       "      <td>1.203708e-01</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>5.207037e-08</td>\n",
       "      <td>1.292489e-03</td>\n",
       "      <td>1.292204e-05</td>\n",
       "      <td>8.783007e-01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>1.620305e-05</td>\n",
       "      <td>9.555512e-05</td>\n",
       "      <td>7.779575e-04</td>\n",
       "      <td>3.633918e-04</td>\n",
       "      <td>4.700170e-07</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>2.369462e-07</td>\n",
       "      <td>3.091300e-08</td>\n",
       "      <td>9.977885e-01</td>\n",
       "      <td>8.100626e-06</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1.977301e-06</td>\n",
       "      <td>1.006029e-09</td>\n",
       "      <td>6.982867e-05</td>\n",
       "      <td>9.998166e-01</td>\n",
       "      <td>1.563408e-08</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>5.614891e-10</td>\n",
       "      <td>2.345672e-10</td>\n",
       "      <td>1.027183e-05</td>\n",
       "      <td>1.809892e-07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>2.457090e-04</td>\n",
       "      <td>3.030905e-06</td>\n",
       "      <td>8.145264e-09</td>\n",
       "      <td>1.969892e-04</td>\n",
       "      <td>1.911397e-06</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>2.562465e-08</td>\n",
       "      <td>3.228659e-06</td>\n",
       "      <td>9.674278e-04</td>\n",
       "      <td>1.748055e-03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>1.184250e-01</td>\n",
       "      <td>2.197596e-07</td>\n",
       "      <td>1.836366e-03</td>\n",
       "      <td>1.010854e-05</td>\n",
       "      <td>9.749688e-04</td>\n",
       "      <td>0.079424</td>\n",
       "      <td>7.993060e-01</td>\n",
       "      <td>4.331422e-07</td>\n",
       "      <td>7.809691e-06</td>\n",
       "      <td>1.537675e-05</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>4.919505e-02</td>\n",
       "      <td>6.933881e-05</td>\n",
       "      <td>2.729280e-05</td>\n",
       "      <td>4.557489e-06</td>\n",
       "      <td>4.278278e-05</td>\n",
       "      <td>0.100376</td>\n",
       "      <td>1.199707e-04</td>\n",
       "      <td>2.266573e-03</td>\n",
       "      <td>8.295035e-01</td>\n",
       "      <td>1.839520e-02</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "0      5.009928e-03  7.469503e-06  1.242133e-02  5.613064e-01  1.004791e-07   \n",
       "1      9.990822e-01  2.948407e-16  1.438319e-11  1.364113e-11  6.809391e-13   \n",
       "2      8.984737e-05  4.445837e-11  1.486989e-06  3.889900e-04  6.483795e-01   \n",
       "3      5.455174e-07  9.844857e-01  9.453045e-04  7.356701e-06  7.178605e-06   \n",
       "4      1.702829e-09  1.626378e-07  1.095382e-10  8.777641e-10  1.203708e-01   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "59995  1.620305e-05  9.555512e-05  7.779575e-04  3.633918e-04  4.700170e-07   \n",
       "59996  1.977301e-06  1.006029e-09  6.982867e-05  9.998166e-01  1.563408e-08   \n",
       "59997  2.457090e-04  3.030905e-06  8.145264e-09  1.969892e-04  1.911397e-06   \n",
       "59998  1.184250e-01  2.197596e-07  1.836366e-03  1.010854e-05  9.749688e-04   \n",
       "59999  4.919505e-02  6.933881e-05  2.729280e-05  4.557489e-06  4.278278e-05   \n",
       "\n",
       "              5             6             7             8             9  \\\n",
       "0      0.396970  2.022694e-04  4.241157e-03  1.822945e-02  1.611490e-03   \n",
       "1      0.000918  1.329700e-08  1.075142e-10  3.041454e-09  1.223539e-11   \n",
       "2      0.000393  4.275278e-06  1.129403e-03  2.429402e-05  3.495889e-01   \n",
       "3      0.000150  3.769938e-05  4.704677e-05  1.431262e-02  6.472946e-06   \n",
       "4      0.000023  5.207037e-08  1.292489e-03  1.292204e-05  8.783007e-01   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "59995  0.000950  2.369462e-07  3.091300e-08  9.977885e-01  8.100626e-06   \n",
       "59996  0.000101  5.614891e-10  2.345672e-10  1.027183e-05  1.809892e-07   \n",
       "59997  0.996834  2.562465e-08  3.228659e-06  9.674278e-04  1.748055e-03   \n",
       "59998  0.079424  7.993060e-01  4.331422e-07  7.809691e-06  1.537675e-05   \n",
       "59999  0.100376  1.199707e-04  2.266573e-03  8.295035e-01  1.839520e-02   \n",
       "\n",
       "       prediction  \n",
       "0               3  \n",
       "1               0  \n",
       "2               4  \n",
       "3               1  \n",
       "4               9  \n",
       "...           ...  \n",
       "59995           8  \n",
       "59996           3  \n",
       "59997           5  \n",
       "59998           6  \n",
       "59999           8  \n",
       "\n",
       "[60000 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = lin_class.forward(embeddings)\n",
    "Y_pred = pd.DataFrame(Y_pred.detach().numpy())\n",
    "Y_pred[\"prediction\"] = Y_pred.apply(np.argmax, axis=1)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f42ea6cc668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(accuracy_score(Y, Y_pred.prediction))\n",
    "conf_mat = confusion_matrix(Y, Y_pred.prediction)\n",
    "plt.matshow(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 5)\n",
      "(110, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168139</td>\n",
       "      <td>8.607004</td>\n",
       "      <td>10.544548</td>\n",
       "      <td>-1.875861</td>\n",
       "      <td>14.947199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168139</td>\n",
       "      <td>6.774639</td>\n",
       "      <td>9.453935</td>\n",
       "      <td>-2.074166</td>\n",
       "      <td>12.493588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251833</td>\n",
       "      <td>6.245407</td>\n",
       "      <td>2.204583</td>\n",
       "      <td>-9.917317</td>\n",
       "      <td>2.996176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251833</td>\n",
       "      <td>8.898745</td>\n",
       "      <td>3.464000</td>\n",
       "      <td>-8.458150</td>\n",
       "      <td>6.950223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121719</td>\n",
       "      <td>8.805327</td>\n",
       "      <td>2.511324</td>\n",
       "      <td>-8.323596</td>\n",
       "      <td>8.753686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>618952</td>\n",
       "      <td>2.615529</td>\n",
       "      <td>-3.292192</td>\n",
       "      <td>-12.578430</td>\n",
       "      <td>1.889788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>189349</td>\n",
       "      <td>3.607781</td>\n",
       "      <td>-3.065661</td>\n",
       "      <td>-8.625574</td>\n",
       "      <td>9.827278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>189349</td>\n",
       "      <td>3.794838</td>\n",
       "      <td>-2.817605</td>\n",
       "      <td>-8.389682</td>\n",
       "      <td>10.302524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>140925</td>\n",
       "      <td>9.012708</td>\n",
       "      <td>0.697612</td>\n",
       "      <td>-9.146828</td>\n",
       "      <td>9.339451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>140925</td>\n",
       "      <td>6.532035</td>\n",
       "      <td>-0.521309</td>\n",
       "      <td>-10.282063</td>\n",
       "      <td>5.810057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      dim1       dim2       dim3       dim4\n",
       "0     168139  8.607004  10.544548  -1.875861  14.947199\n",
       "1     168139  6.774639   9.453935  -2.074166  12.493588\n",
       "2     251833  6.245407   2.204583  -9.917317   2.996176\n",
       "3     251833  8.898745   3.464000  -8.458150   6.950223\n",
       "4     121719  8.805327   2.511324  -8.323596   8.753686\n",
       "...      ...       ...        ...        ...        ...\n",
       "1095  618952  2.615529  -3.292192 -12.578430   1.889788\n",
       "1096  189349  3.607781  -3.065661  -8.625574   9.827278\n",
       "1097  189349  3.794838  -2.817605  -8.389682  10.302524\n",
       "1098  140925  9.012708   0.697612  -9.146828   9.339451\n",
       "1099  140925  6.532035  -0.521309 -10.282063   5.810057\n",
       "\n",
       "[1100 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because the embeddings are not calculated through Visualization, each element is present twice\n",
    "dir_path = '/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/Output/2022-05-18/11-00-10'\n",
    "\n",
    "train_embeddings = pd.read_csv(dir_path+'/train_embeddings.csv', index_col=0)\n",
    "val_embeddings = pd.read_csv(dir_path+'/val_embeddings.csv', index_col=0)\n",
    "\n",
    "print(train_embeddings.shape)\n",
    "print(val_embeddings.shape)\n",
    "\n",
    "\n",
    "embeddings = pd.concat([train_embeddings, val_embeddings], axis=0, ignore_index=True)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.607004</td>\n",
       "      <td>10.544548</td>\n",
       "      <td>-1.875861</td>\n",
       "      <td>14.947199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.774639</td>\n",
       "      <td>9.453935</td>\n",
       "      <td>-2.074166</td>\n",
       "      <td>12.493588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.245407</td>\n",
       "      <td>2.204583</td>\n",
       "      <td>-9.917317</td>\n",
       "      <td>2.996176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.898745</td>\n",
       "      <td>3.464000</td>\n",
       "      <td>-8.458150</td>\n",
       "      <td>6.950223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.805327</td>\n",
       "      <td>2.511324</td>\n",
       "      <td>-8.323596</td>\n",
       "      <td>8.753686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2.615529</td>\n",
       "      <td>-3.292192</td>\n",
       "      <td>-12.578430</td>\n",
       "      <td>1.889788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>3.607781</td>\n",
       "      <td>-3.065661</td>\n",
       "      <td>-8.625574</td>\n",
       "      <td>9.827278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>3.794838</td>\n",
       "      <td>-2.817605</td>\n",
       "      <td>-8.389682</td>\n",
       "      <td>10.302524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>9.012708</td>\n",
       "      <td>0.697612</td>\n",
       "      <td>-9.146828</td>\n",
       "      <td>9.339451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>6.532035</td>\n",
       "      <td>-0.521309</td>\n",
       "      <td>-10.282063</td>\n",
       "      <td>5.810057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dim1       dim2       dim3       dim4\n",
       "0     8.607004  10.544548  -1.875861  14.947199\n",
       "1     6.774639   9.453935  -2.074166  12.493588\n",
       "2     6.245407   2.204583  -9.917317   2.996176\n",
       "3     8.898745   3.464000  -8.458150   6.950223\n",
       "4     8.805327   2.511324  -8.323596   8.753686\n",
       "...        ...        ...        ...        ...\n",
       "1095  2.615529  -3.292192 -12.578430   1.889788\n",
       "1096  3.607781  -3.065661  -8.625574   9.827278\n",
       "1097  3.794838  -2.817605  -8.389682  10.302524\n",
       "1098  9.012708   0.697612  -9.146828   9.339451\n",
       "1099  6.532035  -0.521309 -10.282063   5.810057\n",
       "\n",
       "[1100 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.loc[:, embeddings.columns != 'ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100307</th>\n",
       "      <td>4.518542</td>\n",
       "      <td>-1.731114</td>\n",
       "      <td>-10.004573</td>\n",
       "      <td>5.222970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100610</th>\n",
       "      <td>14.314068</td>\n",
       "      <td>8.940447</td>\n",
       "      <td>-3.657568</td>\n",
       "      <td>18.687688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101107</th>\n",
       "      <td>10.880040</td>\n",
       "      <td>3.124564</td>\n",
       "      <td>-7.629962</td>\n",
       "      <td>10.815388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101309</th>\n",
       "      <td>0.802435</td>\n",
       "      <td>-5.053474</td>\n",
       "      <td>-11.944574</td>\n",
       "      <td>2.161026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102008</th>\n",
       "      <td>9.271605</td>\n",
       "      <td>0.505080</td>\n",
       "      <td>-8.369234</td>\n",
       "      <td>9.781714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973770</th>\n",
       "      <td>9.259984</td>\n",
       "      <td>4.759903</td>\n",
       "      <td>-3.897219</td>\n",
       "      <td>17.227477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987074</th>\n",
       "      <td>14.558414</td>\n",
       "      <td>7.464320</td>\n",
       "      <td>-4.294970</td>\n",
       "      <td>19.736421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987983</th>\n",
       "      <td>0.022700</td>\n",
       "      <td>-4.455080</td>\n",
       "      <td>-13.534734</td>\n",
       "      <td>-1.307830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993675</th>\n",
       "      <td>14.123613</td>\n",
       "      <td>6.539686</td>\n",
       "      <td>-5.165825</td>\n",
       "      <td>17.418071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994273</th>\n",
       "      <td>9.266966</td>\n",
       "      <td>11.298843</td>\n",
       "      <td>-2.479610</td>\n",
       "      <td>14.473982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dim1       dim2       dim3       dim4\n",
       "ID                                                \n",
       "100307   4.518542  -1.731114 -10.004573   5.222970\n",
       "100610  14.314068   8.940447  -3.657568  18.687688\n",
       "101107  10.880040   3.124564  -7.629962  10.815388\n",
       "101309   0.802435  -5.053474 -11.944574   2.161026\n",
       "102008   9.271605   0.505080  -8.369234   9.781714\n",
       "...           ...        ...        ...        ...\n",
       "973770   9.259984   4.759903  -3.897219  17.227477\n",
       "987074  14.558414   7.464320  -4.294970  19.736421\n",
       "987983   0.022700  -4.455080 -13.534734  -1.307830\n",
       "993675  14.123613   6.539686  -5.165825  17.418071\n",
       "994273   9.266966  11.298843  -2.479610  14.473982\n",
       "\n",
       "[550 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the mean of the two representations\n",
    "embeddings = embeddings.groupby(['ID']).mean()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save fake labels to test train_classifier\n",
    "dir_path = \"/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/\\\n",
    "Output/2022-05-18/11-00-10/\"  # should be passed as an argument/ in config\n",
    "train_embeddings = pd.read_csv(dir_path+'train_embeddings.csv', index_col=0)\n",
    "val_embeddings = pd.read_csv(dir_path+'val_embeddings.csv', index_col=0)\n",
    "\n",
    "embeddings = pd.concat([train_embeddings, val_embeddings],#, test_embeddings],\n",
    "                        axis=0, ignore_index=True)\n",
    "embeddings.sort_values(by='ID', inplace=True)\n",
    "\n",
    "ids = embeddings.ID.values\n",
    "\n",
    "labels = pd.DataFrame({'ID': ids,\n",
    "                       'label': np.random.randint(0,2,len(ids))})\n",
    "labels.to_csv(\"fake_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  4.5185,  -1.7311, -10.0046,   5.2230],\n",
       "        [ 14.3141,   8.9404,  -3.6576,  18.6877],\n",
       "        [ 10.8800,   3.1246,  -7.6300,  10.8154],\n",
       "        ...,\n",
       "        [  0.0227,  -4.4551, -13.5347,  -1.3078],\n",
       "        [ 14.1236,   6.5397,  -5.1658,  17.4181],\n",
       "        [  9.2670,  11.2988,  -2.4796,  14.4740]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate fake labels\n",
    "\n",
    "labels = np.random.randint(0,2,550)\n",
    "labels = torch.from_numpy(labels).type(torch.FloatTensor)\n",
    "print(labels[:10])\n",
    "\n",
    "# change dtype of embeddings for the next cells to work\n",
    "embeddings = torch.from_numpy(embeddings.values).type(torch.FloatTensor)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier\n",
    "\n",
    "class BinaryClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, activation=None):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Linear(input_size, output_size)\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            self.activation = None\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        output = self.layer0(x)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        output = self.forward(x)\n",
    "        loss = self.loss(output.reshape(y.shape), y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name   | Type    | Params\n",
      "-----------------------------------\n",
      "0 | layer0 | Linear  | 5     \n",
      "1 | loss   | MSELoss | 0     \n",
      "-----------------------------------\n",
      "5         Trainable params\n",
      "0         Non-trainable params\n",
      "5         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/2022_jchavas_cingulate_inhibitory_control/venv_local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7697a34f664d298238da542c707475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_class = BinaryClassifier(4,1)\n",
    "\n",
    "train_set = TensorDataset(embeddings, labels)\n",
    "train_loader_lin = DataLoader(train_set, batch_size=10)\n",
    "\n",
    "trainer_lin = pl.Trainer(max_epochs=5)\n",
    "trainer_lin.fit(model=bin_class, train_dataloaders=train_loader_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f42e5f94b00>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_pred = bin_class.forward(embeddings)\n",
    "labels_pred = labels_pred.detach().numpy()\n",
    "curves = roc_curve(labels.detach_().numpy(), labels_pred)\n",
    "roc_auc = roc_auc_score(labels.detach_().numpy(), labels_pred)\n",
    "\n",
    "plt.plot(curves[0], curves[1], label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0,1],[0,1],color='r')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests on pd.join "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est de la merde, ca met pas les lignes dans le bon ordre, je sais pas pourquoi (ça le fait pour des exemples plus petits). Utiliser sort_values à la place"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a11d766e9d9d540503ea14849c3c4908afaa53a8fae76fa5fd392b0740cea37"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv_local': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

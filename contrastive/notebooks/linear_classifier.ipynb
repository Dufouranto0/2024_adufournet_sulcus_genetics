{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch-lightning.readthedocs.io/en/stable/starter/introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve,\\\n",
    "roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, latent_space_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, latent_space_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(latent_space_dim, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.encoder(x)\n",
    "        output = self.decoder(embedding)\n",
    "        return output\n",
    "\n",
    "    def forward_embedding(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "# init model\n",
    "latent_space_dim = 15\n",
    "autoencoder = LitAutoEncoder(latent_space_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/2022_jchavas_cingulate_inhibitory_control/venv_local/lib/python3.6/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 51.2 K\n",
      "1 | decoder | Sequential | 52.0 K\n",
      "---------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.413     Total estimated model params size (MB)\n",
      "/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/2022_jchavas_cingulate_inhibitory_control/venv_local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd0239f60c14493a7efa9d885e7a117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "# most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
    "# trainer = pl.Trainer(accelerator=\"gpu\", devices=8) (if you have GPUs)\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_X_y_loader = DataLoader(dataset, batch_size=60000)\n",
    "\n",
    "X,Y = list(get_X_y_loader)[0]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 55\n",
    "\n",
    "outputs = autoencoder.forward(X[i].flatten())\n",
    "outputs = outputs.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f726985f668>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X[i][0])\n",
    "plt.figure()\n",
    "plt.matshow(outputs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0652e+00,  5.7774e-01,  8.8782e-01,  1.2906e+00,  4.1393e-01,\n",
       "          4.2344e-01,  1.3260e-01,  2.4308e-01, -8.0100e-02, -8.7767e-01,\n",
       "          3.5477e-02, -3.1764e-01, -1.6040e-01,  9.4677e-01,  4.5412e-01],\n",
       "        [ 9.2933e-01, -7.1269e-01,  1.5203e-01,  8.4789e-01,  1.4557e-01,\n",
       "          6.8219e-01, -9.9814e-01, -9.7807e-01,  4.8012e-01,  7.4799e-01,\n",
       "          5.2460e-01,  2.0362e-01,  5.8928e-01,  2.2480e+00,  4.8297e-03],\n",
       "        [-4.2706e-01,  6.8885e-01, -7.9994e-02, -9.3204e-02,  2.2164e-01,\n",
       "          5.8952e-02,  1.5688e-01, -9.8718e-01,  1.3592e+00,  1.4906e-02,\n",
       "          1.6534e-01,  1.4995e-01,  8.4817e-01,  2.9356e-02, -3.9766e-01],\n",
       "        [ 5.1431e-01, -1.0181e+00, -4.6320e-01, -1.0944e+00,  8.5950e-01,\n",
       "          4.4725e-01,  7.6085e-01,  7.9462e-01, -4.5343e-01,  4.1263e-01,\n",
       "          1.0064e-01,  1.4273e+00, -5.9479e-01,  8.6152e-01,  4.9957e-01],\n",
       "        [-8.4635e-01, -1.0140e-01,  1.6315e-01,  1.4602e-01,  2.5892e-02,\n",
       "          2.3095e-02,  1.0114e-01,  5.7263e-01,  1.4103e+00,  8.7173e-01,\n",
       "          8.1412e-01,  1.0553e+00, -7.1336e-01,  2.3972e-01,  1.3223e+00],\n",
       "        [ 6.9620e-01,  3.8034e-01, -9.8225e-01,  2.0587e-01,  6.0782e-01,\n",
       "          7.8438e-01,  2.1605e-01, -1.2842e+00,  9.4534e-01, -5.1337e-02,\n",
       "          1.0109e+00,  1.8256e-01, -2.1010e-01,  1.2655e+00,  3.6532e-01],\n",
       "        [ 7.4069e-01,  1.6274e+00,  9.3872e-02,  3.9943e-02, -5.2496e-01,\n",
       "         -6.4349e-01, -4.9822e-02,  1.3175e+00,  1.4957e-01, -9.5927e-01,\n",
       "         -9.2486e-01, -6.5203e-01, -9.4399e-01, -3.2439e-01,  3.7862e-01],\n",
       "        [ 5.8218e-01,  1.1988e-01,  1.3619e+00,  1.0502e+00,  1.4883e+00,\n",
       "          6.6079e-01,  6.4665e-01, -3.9904e-01,  6.4524e-01, -1.6590e+00,\n",
       "          1.3208e-03,  5.2256e-01,  5.3626e-01,  1.1471e+00,  3.9060e-01],\n",
       "        [ 7.1536e-01,  8.9186e-01,  1.0993e-01,  1.7204e-01, -6.5218e-01,\n",
       "         -5.3404e-01, -4.6099e-02,  1.0134e+00,  4.9296e-01, -6.5484e-01,\n",
       "         -3.7963e-01, -6.4324e-01, -1.0640e+00, -3.5123e-01, -6.1578e-02],\n",
       "        [ 5.8582e-01, -1.1265e-01, -5.9097e-01,  8.1531e-01, -2.5152e-01,\n",
       "         -1.4765e-01,  9.0752e-01, -1.1201e-01,  1.3635e+00,  2.6825e-01,\n",
       "          5.7240e-01,  5.5781e-01,  2.9532e-01,  3.5233e-01, -3.1596e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.forward_embedding(X[:10].flatten(start_dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Linear(input_size, output_size)\n",
    "        self.activation0 = nn.Softmax(dim=1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        output = self.layer0(x)\n",
    "        output = self.activation0(output)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        output = self.forward(x)\n",
    "        loss = self.loss(output, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the linear classifier\n",
    "lin_class = LinearClassifier(latent_space_dim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0652e+00,  5.7774e-01,  8.8782e-01,  1.2906e+00,  4.1393e-01,\n",
      "          4.2344e-01,  1.3260e-01,  2.4308e-01, -8.0100e-02, -8.7767e-01,\n",
      "          3.5477e-02, -3.1764e-01, -1.6040e-01,  9.4677e-01,  4.5412e-01],\n",
      "        [ 9.2933e-01, -7.1269e-01,  1.5203e-01,  8.4789e-01,  1.4557e-01,\n",
      "          6.8219e-01, -9.9814e-01, -9.7807e-01,  4.8012e-01,  7.4799e-01,\n",
      "          5.2460e-01,  2.0362e-01,  5.8928e-01,  2.2480e+00,  4.8297e-03],\n",
      "        [-4.2706e-01,  6.8885e-01, -7.9994e-02, -9.3204e-02,  2.2164e-01,\n",
      "          5.8953e-02,  1.5688e-01, -9.8718e-01,  1.3592e+00,  1.4906e-02,\n",
      "          1.6534e-01,  1.4995e-01,  8.4817e-01,  2.9356e-02, -3.9766e-01],\n",
      "        [ 5.1431e-01, -1.0181e+00, -4.6320e-01, -1.0944e+00,  8.5950e-01,\n",
      "          4.4725e-01,  7.6085e-01,  7.9462e-01, -4.5343e-01,  4.1263e-01,\n",
      "          1.0064e-01,  1.4273e+00, -5.9479e-01,  8.6152e-01,  4.9957e-01],\n",
      "        [-8.4635e-01, -1.0140e-01,  1.6315e-01,  1.4602e-01,  2.5892e-02,\n",
      "          2.3095e-02,  1.0114e-01,  5.7263e-01,  1.4103e+00,  8.7173e-01,\n",
      "          8.1412e-01,  1.0553e+00, -7.1336e-01,  2.3972e-01,  1.3223e+00],\n",
      "        [ 6.9620e-01,  3.8034e-01, -9.8225e-01,  2.0587e-01,  6.0782e-01,\n",
      "          7.8438e-01,  2.1605e-01, -1.2842e+00,  9.4534e-01, -5.1337e-02,\n",
      "          1.0109e+00,  1.8256e-01, -2.1010e-01,  1.2655e+00,  3.6532e-01],\n",
      "        [ 7.4069e-01,  1.6274e+00,  9.3872e-02,  3.9943e-02, -5.2496e-01,\n",
      "         -6.4349e-01, -4.9822e-02,  1.3175e+00,  1.4957e-01, -9.5927e-01,\n",
      "         -9.2486e-01, -6.5203e-01, -9.4399e-01, -3.2439e-01,  3.7862e-01],\n",
      "        [ 5.8218e-01,  1.1988e-01,  1.3619e+00,  1.0502e+00,  1.4883e+00,\n",
      "          6.6079e-01,  6.4665e-01, -3.9904e-01,  6.4524e-01, -1.6590e+00,\n",
      "          1.3208e-03,  5.2256e-01,  5.3626e-01,  1.1471e+00,  3.9060e-01],\n",
      "        [ 7.1536e-01,  8.9186e-01,  1.0993e-01,  1.7204e-01, -6.5218e-01,\n",
      "         -5.3404e-01, -4.6099e-02,  1.0134e+00,  4.9296e-01, -6.5484e-01,\n",
      "         -3.7963e-01, -6.4324e-01, -1.0640e+00, -3.5123e-01, -6.1578e-02],\n",
      "        [ 5.8582e-01, -1.1265e-01, -5.9097e-01,  8.1531e-01, -2.5152e-01,\n",
      "         -1.4765e-01,  9.0752e-01, -1.1201e-01,  1.3635e+00,  2.6825e-01,\n",
      "          5.7240e-01,  5.5781e-01,  2.9532e-01,  3.5233e-01, -3.1596e-01]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# create its dataset\n",
    "X_propag = X.flatten(start_dim=1)\n",
    "embeddings = autoencoder.forward_embedding(X_propag)\n",
    "embeddings.detach_()\n",
    "print(embeddings[:10])\n",
    "\n",
    "# apparently no need\n",
    "Y_one_hot = F.one_hot(Y).type(torch.FloatTensor)\n",
    "print(Y_one_hot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | layer0      | Linear           | 160   \n",
      "1 | activation0 | Softmax          | 0     \n",
      "2 | loss        | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "160       Trainable params\n",
      "0         Non-trainable params\n",
      "160       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95fdc8b84c64f8d9861095aecd95e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the linear classifier on the latent space embedding\n",
    "\n",
    "train_set = TensorDataset(embeddings, Y)\n",
    "train_loader_lin = DataLoader(train_set, batch_size=10)\n",
    "\n",
    "trainer_lin = pl.Trainer(max_epochs=5)\n",
    "trainer_lin.fit(model=lin_class, train_dataloaders=train_loader_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>1.492389e-06</td>\n",
       "      <td>3.926176e-04</td>\n",
       "      <td>2.706233e-01</td>\n",
       "      <td>1.020969e-07</td>\n",
       "      <td>0.726693</td>\n",
       "      <td>2.578622e-06</td>\n",
       "      <td>4.179239e-06</td>\n",
       "      <td>1.925494e-03</td>\n",
       "      <td>1.217575e-04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999955</td>\n",
       "      <td>5.939976e-15</td>\n",
       "      <td>1.386806e-10</td>\n",
       "      <td>1.544870e-10</td>\n",
       "      <td>7.218954e-12</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.624676e-09</td>\n",
       "      <td>7.910735e-12</td>\n",
       "      <td>1.270164e-09</td>\n",
       "      <td>9.098839e-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001181</td>\n",
       "      <td>1.323174e-06</td>\n",
       "      <td>2.479436e-04</td>\n",
       "      <td>1.659138e-03</td>\n",
       "      <td>9.501346e-01</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>2.269879e-04</td>\n",
       "      <td>9.394144e-05</td>\n",
       "      <td>1.066469e-03</td>\n",
       "      <td>4.423593e-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>9.832885e-01</td>\n",
       "      <td>4.827475e-04</td>\n",
       "      <td>3.962046e-05</td>\n",
       "      <td>6.308584e-05</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>3.174072e-06</td>\n",
       "      <td>4.448861e-05</td>\n",
       "      <td>1.571888e-02</td>\n",
       "      <td>6.767474e-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.940176e-08</td>\n",
       "      <td>1.994107e-09</td>\n",
       "      <td>3.130602e-09</td>\n",
       "      <td>7.228050e-02</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>4.772648e-06</td>\n",
       "      <td>5.963410e-04</td>\n",
       "      <td>1.104990e-04</td>\n",
       "      <td>9.269239e-01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.475223e-04</td>\n",
       "      <td>1.198919e-04</td>\n",
       "      <td>1.793856e-04</td>\n",
       "      <td>4.379055e-06</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>2.449819e-07</td>\n",
       "      <td>1.526841e-08</td>\n",
       "      <td>9.991409e-01</td>\n",
       "      <td>3.122910e-05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.703338e-07</td>\n",
       "      <td>4.611711e-05</td>\n",
       "      <td>9.999015e-01</td>\n",
       "      <td>1.248182e-08</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>2.129452e-10</td>\n",
       "      <td>5.628963e-11</td>\n",
       "      <td>1.882409e-05</td>\n",
       "      <td>1.317905e-08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.348071e-07</td>\n",
       "      <td>2.067665e-09</td>\n",
       "      <td>1.165918e-04</td>\n",
       "      <td>1.129460e-05</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>8.309184e-09</td>\n",
       "      <td>3.993783e-06</td>\n",
       "      <td>6.953017e-04</td>\n",
       "      <td>1.017734e-03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.188639</td>\n",
       "      <td>3.198406e-07</td>\n",
       "      <td>1.245405e-03</td>\n",
       "      <td>1.171091e-06</td>\n",
       "      <td>1.081957e-03</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>8.041490e-01</td>\n",
       "      <td>1.209496e-06</td>\n",
       "      <td>5.986405e-07</td>\n",
       "      <td>1.803149e-04</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.056174</td>\n",
       "      <td>2.052679e-03</td>\n",
       "      <td>2.770191e-03</td>\n",
       "      <td>4.979627e-04</td>\n",
       "      <td>8.377719e-04</td>\n",
       "      <td>0.047045</td>\n",
       "      <td>5.140829e-04</td>\n",
       "      <td>1.254237e-03</td>\n",
       "      <td>7.462958e-01</td>\n",
       "      <td>1.425581e-01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0      0.000236  1.492389e-06  3.926176e-04  2.706233e-01  1.020969e-07   \n",
       "1      0.999955  5.939976e-15  1.386806e-10  1.544870e-10  7.218954e-12   \n",
       "2      0.001181  1.323174e-06  2.479436e-04  1.659138e-03  9.501346e-01   \n",
       "3      0.000085  9.832885e-01  4.827475e-04  3.962046e-05  6.308584e-05   \n",
       "4      0.000001  1.940176e-08  1.994107e-09  3.130602e-09  7.228050e-02   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "59995  0.000005  2.475223e-04  1.198919e-04  1.793856e-04  4.379055e-06   \n",
       "59996  0.000001  3.703338e-07  4.611711e-05  9.999015e-01  1.248182e-08   \n",
       "59997  0.000004  2.348071e-07  2.067665e-09  1.165918e-04  1.129460e-05   \n",
       "59998  0.188639  3.198406e-07  1.245405e-03  1.171091e-06  1.081957e-03   \n",
       "59999  0.056174  2.052679e-03  2.770191e-03  4.979627e-04  8.377719e-04   \n",
       "\n",
       "              5             6             7             8             9  \\\n",
       "0      0.726693  2.578622e-06  4.179239e-06  1.925494e-03  1.217575e-04   \n",
       "1      0.000045  9.624676e-09  7.910735e-12  1.270164e-09  9.098839e-10   \n",
       "2      0.001153  2.269879e-04  9.394144e-05  1.066469e-03  4.423593e-02   \n",
       "3      0.000268  3.174072e-06  4.448861e-05  1.571888e-02  6.767474e-06   \n",
       "4      0.000083  4.772648e-06  5.963410e-04  1.104990e-04  9.269239e-01   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "59995  0.000272  2.449819e-07  1.526841e-08  9.991409e-01  3.122910e-05   \n",
       "59996  0.000032  2.129452e-10  5.628963e-11  1.882409e-05  1.317905e-08   \n",
       "59997  0.998151  8.309184e-09  3.993783e-06  6.953017e-04  1.017734e-03   \n",
       "59998  0.004701  8.041490e-01  1.209496e-06  5.986405e-07  1.803149e-04   \n",
       "59999  0.047045  5.140829e-04  1.254237e-03  7.462958e-01  1.425581e-01   \n",
       "\n",
       "       prediction  \n",
       "0               5  \n",
       "1               0  \n",
       "2               4  \n",
       "3               1  \n",
       "4               9  \n",
       "...           ...  \n",
       "59995           8  \n",
       "59996           3  \n",
       "59997           5  \n",
       "59998           6  \n",
       "59999           8  \n",
       "\n",
       "[60000 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = lin_class.forward(embeddings)\n",
    "Y_pred = pd.DataFrame(Y_pred.detach().numpy())\n",
    "Y_pred[\"prediction\"] = Y_pred.apply(np.argmax, axis=1)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f726b41b4e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(accuracy_score(Y, Y_pred.prediction))\n",
    "conf_mat = confusion_matrix(Y, Y_pred.prediction)\n",
    "plt.matshow(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880, 5)\n",
      "(220, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144226</td>\n",
       "      <td>-2.207053</td>\n",
       "      <td>2.572717</td>\n",
       "      <td>-3.648947</td>\n",
       "      <td>-0.379905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144226</td>\n",
       "      <td>-2.268051</td>\n",
       "      <td>2.614371</td>\n",
       "      <td>-3.520722</td>\n",
       "      <td>-0.138869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303624</td>\n",
       "      <td>12.872168</td>\n",
       "      <td>6.815033</td>\n",
       "      <td>-5.646133</td>\n",
       "      <td>14.380918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303624</td>\n",
       "      <td>12.459433</td>\n",
       "      <td>8.353728</td>\n",
       "      <td>-4.972514</td>\n",
       "      <td>14.725413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480141</td>\n",
       "      <td>3.699481</td>\n",
       "      <td>-2.619190</td>\n",
       "      <td>-10.280997</td>\n",
       "      <td>4.794017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>212015</td>\n",
       "      <td>8.657934</td>\n",
       "      <td>5.084440</td>\n",
       "      <td>-3.079031</td>\n",
       "      <td>17.102121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>158035</td>\n",
       "      <td>0.528529</td>\n",
       "      <td>3.882899</td>\n",
       "      <td>-2.446297</td>\n",
       "      <td>4.086941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>158035</td>\n",
       "      <td>-0.486430</td>\n",
       "      <td>2.983658</td>\n",
       "      <td>-2.467060</td>\n",
       "      <td>2.725870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>239944</td>\n",
       "      <td>11.371716</td>\n",
       "      <td>8.044619</td>\n",
       "      <td>-2.493785</td>\n",
       "      <td>18.786053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>239944</td>\n",
       "      <td>12.774071</td>\n",
       "      <td>7.724382</td>\n",
       "      <td>-3.009945</td>\n",
       "      <td>18.931105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject       dim1      dim2       dim3       dim4\n",
       "0      144226  -2.207053  2.572717  -3.648947  -0.379905\n",
       "1      144226  -2.268051  2.614371  -3.520722  -0.138869\n",
       "2      303624  12.872168  6.815033  -5.646133  14.380918\n",
       "3      303624  12.459433  8.353728  -4.972514  14.725413\n",
       "4      480141   3.699481 -2.619190 -10.280997   4.794017\n",
       "...       ...        ...       ...        ...        ...\n",
       "1095   212015   8.657934  5.084440  -3.079031  17.102121\n",
       "1096   158035   0.528529  3.882899  -2.446297   4.086941\n",
       "1097   158035  -0.486430  2.983658  -2.467060   2.725870\n",
       "1098   239944  11.371716  8.044619  -2.493785  18.786053\n",
       "1099   239944  12.774071  7.724382  -3.009945  18.931105\n",
       "\n",
       "[1100 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because the embeddings are not calculated through Visualization, each element is present twice\n",
    "dir_path = '/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/Output/2022-05-18/11-00-10'\n",
    "\n",
    "train_embeddings = pd.read_csv(dir_path+'/train_embeddings.csv', index_col=0)\n",
    "val_embeddings = pd.read_csv(dir_path+'/val_embeddings.csv', index_col=0)\n",
    "\n",
    "print(train_embeddings.shape)\n",
    "print(val_embeddings.shape)\n",
    "\n",
    "\n",
    "embeddings = pd.concat([train_embeddings, val_embeddings], axis=0, ignore_index=True)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100307</th>\n",
       "      <td>2.647795</td>\n",
       "      <td>-3.684141</td>\n",
       "      <td>-11.374614</td>\n",
       "      <td>3.588052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100610</th>\n",
       "      <td>14.752218</td>\n",
       "      <td>11.085659</td>\n",
       "      <td>-3.201238</td>\n",
       "      <td>19.024449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101107</th>\n",
       "      <td>12.183602</td>\n",
       "      <td>5.672369</td>\n",
       "      <td>-6.975614</td>\n",
       "      <td>11.922921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101309</th>\n",
       "      <td>3.039796</td>\n",
       "      <td>-3.359846</td>\n",
       "      <td>-9.495158</td>\n",
       "      <td>6.162879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102008</th>\n",
       "      <td>5.510081</td>\n",
       "      <td>-1.798072</td>\n",
       "      <td>-9.784253</td>\n",
       "      <td>5.703923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973770</th>\n",
       "      <td>11.549474</td>\n",
       "      <td>5.100856</td>\n",
       "      <td>-4.246515</td>\n",
       "      <td>19.545314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987074</th>\n",
       "      <td>13.200897</td>\n",
       "      <td>4.419208</td>\n",
       "      <td>-6.361612</td>\n",
       "      <td>15.696317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987983</th>\n",
       "      <td>0.843702</td>\n",
       "      <td>-5.026104</td>\n",
       "      <td>-14.056771</td>\n",
       "      <td>-0.473112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993675</th>\n",
       "      <td>10.565556</td>\n",
       "      <td>2.673657</td>\n",
       "      <td>-7.171947</td>\n",
       "      <td>11.930197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994273</th>\n",
       "      <td>14.897842</td>\n",
       "      <td>11.308544</td>\n",
       "      <td>-2.905897</td>\n",
       "      <td>19.494782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dim1       dim2       dim3       dim4\n",
       "subject                                            \n",
       "100307    2.647795  -3.684141 -11.374614   3.588052\n",
       "100610   14.752218  11.085659  -3.201238  19.024449\n",
       "101107   12.183602   5.672369  -6.975614  11.922921\n",
       "101309    3.039796  -3.359846  -9.495158   6.162879\n",
       "102008    5.510081  -1.798072  -9.784253   5.703923\n",
       "...            ...        ...        ...        ...\n",
       "973770   11.549474   5.100856  -4.246515  19.545314\n",
       "987074   13.200897   4.419208  -6.361612  15.696317\n",
       "987983    0.843702  -5.026104 -14.056771  -0.473112\n",
       "993675   10.565556   2.673657  -7.171947  11.930197\n",
       "994273   14.897842  11.308544  -2.905897  19.494782\n",
       "\n",
       "[550 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the mean of the two representations\n",
    "embeddings = embeddings.groupby(['subject']).mean()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 1., 1., 1., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  2.6478,  -3.6841, -11.3746,   3.5881],\n",
       "        [ 14.7522,  11.0857,  -3.2012,  19.0245],\n",
       "        [ 12.1836,   5.6724,  -6.9756,  11.9229],\n",
       "        ...,\n",
       "        [  0.8437,  -5.0261, -14.0568,  -0.4731],\n",
       "        [ 10.5656,   2.6737,  -7.1719,  11.9302],\n",
       "        [ 14.8978,  11.3085,  -2.9059,  19.4948]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate fake labels\n",
    "\n",
    "labels = np.random.randint(0,2,550)\n",
    "labels = torch.from_numpy(labels).type(torch.FloatTensor)\n",
    "print(labels[:10])\n",
    "\n",
    "# change dtype of embeddings for the next cells to work\n",
    "embeddings = torch.from_numpy(embeddings.values).type(torch.FloatTensor)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier\n",
    "\n",
    "class BinaryClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, activation=None):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Linear(input_size, output_size)\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            self.activation = None\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        output = self.layer0(x)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        output = self.forward(x)\n",
    "        loss = self.loss(output, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name   | Type    | Params\n",
      "-----------------------------------\n",
      "0 | layer0 | Linear  | 5     \n",
      "1 | loss   | MSELoss | 0     \n",
      "-----------------------------------\n",
      "5         Trainable params\n",
      "0         Non-trainable params\n",
      "5         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/2022_jchavas_cingulate_inhibitory_control/venv_local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f40b1ffd3f44809562253c45168145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/neurospin/dico/agaudin/Runs/02_explicabilite_humains_2022/2022_jchavas_cingulate_inhibitory_control/venv_local/lib/python3.6/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "bin_class = BinaryClassifier(4,1)\n",
    "\n",
    "train_set = TensorDataset(embeddings, labels)\n",
    "train_loader_lin = DataLoader(train_set, batch_size=10)\n",
    "\n",
    "trainer_lin = pl.Trainer(max_epochs=5)\n",
    "trainer_lin.fit(model=bin_class, train_dataloaders=train_loader_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f725f311c18>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = labels.detach_().numpy()\n",
    "\n",
    "labels_pred = bin_class.forward(embeddings)\n",
    "labels_pred = labels_pred.detach().numpy()\n",
    "\n",
    "curves = roc_curve(labels, labels_pred)\n",
    "roc_auc = roc_auc_score(labels.detach_().numpy(), labels_pred)\n",
    "\n",
    "plt.plot(curves[0], curves[1], label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0,1],[0,1],color='r')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a11d766e9d9d540503ea14849c3c4908afaa53a8fae76fa5fd392b0740cea37"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv_local': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

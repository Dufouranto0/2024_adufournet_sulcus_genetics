{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from contrastive.backbones.pointnet import PointNetCls\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 17, 40, 38, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28785760"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.product(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870630\n",
      "870630\n",
      "870630\n",
      "870630\n",
      "870630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 1113, 1113, 1113]),\n",
       " array([ 1,  1,  1, ..., 13, 13, 13]),\n",
       " array([ 7,  8,  9, ..., 11, 12, 12]),\n",
       " array([23, 23, 22, ..., 33, 29, 30]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.nonzero(data)\n",
    "for coord in points:\n",
    "    print(len(coord)) # should always be the same\n",
    "\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 912), (3, 711))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clouds = []\n",
    "\n",
    "for i in range(data.shape[0]): # loop over batch elements\n",
    "    point_cloud = np.array(data[i].nonzero()[:3])\n",
    "    clouds.append(point_cloud)\n",
    "\n",
    "clouds[0].shape, clouds[1].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for point_cloud in clouds:\n",
    "    #print(len(point_cloud), len(point_cloud[0]))\n",
    "    lengths.append(point_cloud.shape[1])\n",
    "\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 893), (10, 3, 500))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = [point_cloud for i in range(10)]\n",
    "points = np.array(points)\n",
    "\n",
    "semi_points = [point_cloud[:,:500] for i in range(10)]\n",
    "semi_points = np.array(semi_points)\n",
    "\n",
    "points.shape, semi_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]]]),\n",
       " tensor([[[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.from_numpy(points).type(torch.FloatTensor)\n",
    "semi_X = torch.from_numpy(semi_points).type(torch.FloatTensor)\n",
    "X, semi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─PointNetfeat: 1-1                      --\n",
      "|    └─STN3d: 2-1                        --\n",
      "|    |    └─Conv1d: 3-1                  256\n",
      "|    |    └─Conv1d: 3-2                  8,320\n",
      "|    |    └─Conv1d: 3-3                  132,096\n",
      "|    |    └─Linear: 3-4                  524,800\n",
      "|    |    └─Linear: 3-5                  131,328\n",
      "|    |    └─Linear: 3-6                  2,313\n",
      "|    |    └─ReLU: 3-7                    --\n",
      "|    |    └─BatchNorm1d: 3-8             128\n",
      "|    |    └─BatchNorm1d: 3-9             256\n",
      "|    |    └─BatchNorm1d: 3-10            2,048\n",
      "|    |    └─BatchNorm1d: 3-11            1,024\n",
      "|    |    └─BatchNorm1d: 3-12            512\n",
      "|    └─Conv1d: 2-2                       256\n",
      "|    └─Conv1d: 2-3                       8,320\n",
      "|    └─Conv1d: 2-4                       132,096\n",
      "|    └─BatchNorm1d: 2-5                  128\n",
      "|    └─BatchNorm1d: 2-6                  256\n",
      "|    └─BatchNorm1d: 2-7                  2,048\n",
      "├─Linear: 1-2                            524,800\n",
      "├─Linear: 1-3                            131,328\n",
      "├─Linear: 1-4                            1,028\n",
      "├─Dropout: 1-5                           --\n",
      "├─BatchNorm1d: 1-6                       1,024\n",
      "├─BatchNorm1d: 1-7                       512\n",
      "├─ReLU: 1-8                              --\n",
      "├─Sequential: 1-9                        --\n",
      "|    └─Linear: 2-8                       20\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─Linear: 2-10                      20\n",
      "=================================================================\n",
      "Total params: 1,604,917\n",
      "Trainable params: 1,604,917\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "torch.Size([10, 3, 893]) torch.Size([10, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = PointNetCls(k=4)\n",
    "net.eval()\n",
    "\n",
    "summary(net)\n",
    "\n",
    "Y, trans, trans_feat = net.forward(X)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 500]) torch.Size([10, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = PointNetCls(k=4)\n",
    "#net.eval()\n",
    "\n",
    "semi_Y, trans, trans_feat = net.forward(semi_X)\n",
    "\n",
    "print(semi_X.shape, semi_Y.shape)\n",
    "semi_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accept point clouds with different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/charlesq34/pointnet/issues/161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1080)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zero_padding(cloud, n_max, shuffle=False):\n",
    "    return np.pad(cloud, ((0,0),(0,n_max-cloud.shape[1])))\n",
    "\n",
    "zero_padding(clouds[0], 1080).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1080)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repeat_padding(cloud, n_max, replace=False):\n",
    "    while n_max - cloud.shape[1] > 0: # loop in case len(cloud) < n_max/2\n",
    "        n = min(n_max - cloud.shape[1], cloud.shape[1])\n",
    "        if n < 0:\n",
    "            raise ValueError(\"the vector is too long compared to the desired vector size\")\n",
    "        \n",
    "        idx = np.random.choice(cloud.shape[1], size=n, replace=replace)\n",
    "        padded_part = cloud[:, idx]\n",
    "\n",
    "        cloud = np.concatenate([cloud, padded_part], axis=1)\n",
    "    \n",
    "    return cloud\n",
    "\n",
    "repeat_padding(clouds[0], 1080).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(clouds, padding_method=zero_padding, n_max=None):\n",
    "    if not n_max:\n",
    "        n_max = np.max([clouds[i].shape[1] for i in range(len(clouds))]) # max length of a sequence\n",
    "    padded_clouds = np.array([padding_method(cloud, n_max) for cloud in clouds])\n",
    "    return padded_clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 912), (1114, 3, 1080))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_padded_clouds = pad(clouds[:10], padding_method=zero_padding)\n",
    "r_padded_clouds = pad(clouds, padding_method=repeat_padding)\n",
    "\n",
    "z_padded_clouds.shape, r_padded_clouds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  1,  1, ...,  0,  0,  0],\n",
       "        [ 7,  8,  9, ...,  0,  0,  0],\n",
       "        [23, 23, 22, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 1,  1,  1, ...,  0,  0,  0],\n",
       "        [ 7, 13, 13, ...,  0,  0,  0],\n",
       "        [27, 16, 17, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 1,  2,  2, ...,  0,  0,  0],\n",
       "        [ 6,  5,  5, ...,  0,  0,  0],\n",
       "        [25, 23, 24, ...,  0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1,  1,  1, ...,  0,  0,  0],\n",
       "        [10, 10, 11, ...,  0,  0,  0],\n",
       "        [20, 21, 19, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 3,  3,  3, ...,  0,  0,  0],\n",
       "        [ 3,  9, 10, ...,  0,  0,  0],\n",
       "        [24, 15, 14, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 1,  2,  2, ...,  0,  0,  0],\n",
       "        [11,  9,  9, ...,  0,  0,  0],\n",
       "        [19, 19, 20, ...,  0,  0,  0]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_padded_clouds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1114, 3, 1080])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_padded_X = torch.from_numpy(z_padded_clouds).type(torch.FloatTensor)\n",
    "r_padded_X = torch.from_numpy(r_padded_clouds).type(torch.FloatTensor)\n",
    "z_padded_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6166,  0.4821,  0.3638,  0.2842],\n",
      "        [-0.6140,  0.4804,  0.3583,  0.2798],\n",
      "        [-0.6168,  0.4817,  0.3642,  0.2846],\n",
      "        [-0.6150,  0.4796,  0.3643,  0.2864],\n",
      "        [-0.6104,  0.4754,  0.3635,  0.2895],\n",
      "        [-0.6120,  0.4771,  0.3627,  0.2872],\n",
      "        [-0.6124,  0.4771,  0.3626,  0.2866],\n",
      "        [-0.6155,  0.4799,  0.3623,  0.2836],\n",
      "        [-0.6126,  0.4775,  0.3628,  0.2867],\n",
      "        [-0.6123,  0.4772,  0.3620,  0.2860]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6158,  0.4816,  0.3678,  0.2896],\n",
      "        [-0.6148,  0.4812,  0.3620,  0.2835],\n",
      "        [-0.6156,  0.4806,  0.3677,  0.2899],\n",
      "        [-0.6145,  0.4795,  0.3685,  0.2917],\n",
      "        [-0.6096,  0.4755,  0.3671,  0.2945],\n",
      "        [-0.6117,  0.4775,  0.3662,  0.2914],\n",
      "        [-0.6133,  0.4784,  0.3667,  0.2908],\n",
      "        [-0.6153,  0.4802,  0.3659,  0.2878],\n",
      "        [-0.6120,  0.4776,  0.3667,  0.2919],\n",
      "        [-0.6124,  0.4780,  0.3652,  0.2897]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z_Y, _, _ = net.forward(z_padded_X[:10])\n",
    "r_Y, _, _ = net.forward(r_padded_X[:10])\n",
    "print(z_Y)\n",
    "print(r_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6158,  0.4816,  0.3678,  0.2896]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6148,  0.4812,  0.3620,  0.2835]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6156,  0.4806,  0.3677,  0.2899]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6145,  0.4795,  0.3685,  0.2917]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6096,  0.4755,  0.3671,  0.2945]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6117,  0.4775,  0.3662,  0.2914]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6133,  0.4784,  0.3667,  0.2908]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6153,  0.4802,  0.3659,  0.2878]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6120,  0.4776,  0.3667,  0.2919]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6124,  0.4780,  0.3652,  0.2897]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for cloud in clouds[:10]:\n",
    "    cloud = torch.from_numpy(cloud).type(torch.FloatTensor)\n",
    "    cloud = cloud[None,:,:]  # add a dimension\n",
    "    #print(cloud.shape)\n",
    "    print(net.forward(cloud)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion transform for pointnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from augmentations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToPointnetTensor(object):\n",
    "\n",
    "    def __init__(self, padding_method=repeat_padding, n_max=None):\n",
    "        self.padding_method = padding_method\n",
    "        self.n_max = n_max\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        arr = tensor.numpy()\n",
    "\n",
    "        clouds = []\n",
    "        for i in range(arr.shape[0]): # loop over batch elements\n",
    "            point_cloud = np.array(arr[i].nonzero()[:3])\n",
    "            print(point_cloud.shape)\n",
    "            clouds.append(point_cloud)\n",
    "        \n",
    "        padded_clouds = pad(clouds, padding_method=self.padding_method, n_max=self.n_max)\n",
    "        \n",
    "        return torch.from_numpy(padded_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 17, 40, 38, 1])\n",
      "(3, 912)\n",
      "(3, 711)\n",
      "(3, 799)\n",
      "(3, 702)\n",
      "(3, 636)\n",
      "(3, 659)\n",
      "(3, 775)\n",
      "(3, 897)\n",
      "(3, 836)\n",
      "(3, 767)\n",
      "(3, 874)\n",
      "(3, 906)\n",
      "(3, 923)\n",
      "(3, 721)\n",
      "(3, 803)\n",
      "(3, 609)\n",
      "(3, 854)\n",
      "(3, 844)\n",
      "(3, 870)\n",
      "(3, 677)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 923])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertisseur = ToPointnetTensor(n_max=None)\n",
    "\n",
    "X = torch.from_numpy(data[:20])\n",
    "print(X.size())\n",
    "\n",
    "convertisseur(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15775, 5])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(X, as_tuple=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 912)\n",
      "(3, 711)\n",
      "(3, 799)\n",
      "(3, 702)\n",
      "(3, 636)\n",
      "(3, 659)\n",
      "(3, 775)\n",
      "(3, 897)\n",
      "(3, 836)\n",
      "(3, 767)\n",
      "(3, 874)\n",
      "(3, 906)\n",
      "(3, 923)\n",
      "(3, 721)\n",
      "(3, 803)\n",
      "(3, 609)\n",
      "(3, 854)\n",
      "(3, 844)\n",
      "(3, 870)\n",
      "(3, 677)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(np.array(data[i].nonzero()[:3]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive.data.transforms import transform_no_foldlabel\n",
    "from contrastive.data.datasets import ContrastiveDataset\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkpoint_dir': '../../Output',\n",
       " 'pickle_normal': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.pkl',\n",
       " 'numpy_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.npy',\n",
       " 'subjects_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton_subject.csv',\n",
       " 'foldlabel_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rlabel.npy',\n",
       " 'subjects_foldlabel_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rlabel_subject.csv',\n",
       " 'pickle_benchmark': 'null',\n",
       " 'train_val_csv_file': '/neurospin/dico/data/deep_folding/papers/midl2022/HCP_half_1bis.csv',\n",
       " 'nb_subjects': '-1',\n",
       " 'model': 'SimCLR',\n",
       " 'with_labels': 'false',\n",
       " 'input_size': '(1, 17, 40, 38)',\n",
       " 'temperature_initial': '0.5',\n",
       " 'temperature': '0.5',\n",
       " 'sigma': '5',\n",
       " 'drop_rate': '0.15',\n",
       " 'depth_decoder': '3',\n",
       " 'test': 'false',\n",
       " 'mode': 'encoder',\n",
       " 'foldlabel': 'false',\n",
       " 'fill_value': '0',\n",
       " 'patch_size': ['1', '9', '22', '21'],\n",
       " 'max_angle': '10',\n",
       " 'checkerboard_size': '4',\n",
       " 'keep_bottom': 'true',\n",
       " 'backbone_name': 'convnet',\n",
       " 'encoder_depth': '3',\n",
       " 'num_representation_features': '12',\n",
       " 'num_outputs': '30',\n",
       " 'projection_head_dims': 'null',\n",
       " 'device': 'cuda',\n",
       " 'num_cpu_workers': '16',\n",
       " 'environment': 'not_brainvisa',\n",
       " 'batch_size': '16',\n",
       " 'pin_mem': 'true',\n",
       " 'partition': ['0.9', '0.1'],\n",
       " 'lr': '0.0004',\n",
       " 'weight_decay': '5.0e-05',\n",
       " 'max_epochs': '20',\n",
       " 'nb_epochs_per_saving': '1',\n",
       " 'nb_epochs_per_tSNE': '50',\n",
       " 'nb_steps_per_flush_logs': '1',\n",
       " 'log_every_n_steps': '2',\n",
       " 'early_stopping_patience': '100',\n",
       " 'seed': '1',\n",
       " 'start_epoch': '0',\n",
       " 'checkpoint_path': 'null',\n",
       " 'analysis_path': 'null',\n",
       " 'verbose': '1',\n",
       " 'classifier_name': 'svm',\n",
       " 'training_embeddings': '/neurospin/dico/agaudin/Runs/03_monkeys/Output/analysis_folders/pca/30/Run1/pca_embeddings.csv',\n",
       " 'embeddings_of_interest': 'null',\n",
       " 'results_save_path': 'null',\n",
       " 'training_labels': '/neurospin/dico/data/bv_databases/human/partially_labeled/ACCpatterns/all.csv',\n",
       " 'labels_of_interest': 'null',\n",
       " 'class_max_epochs': '5000',\n",
       " 'n_repeat': '250',\n",
       " 'classifier_seed': '24',\n",
       " 'classifier_test_size': '0.2',\n",
       " 'model_path': '/neurospin/dico/agaudin/Runs/04_pointnet/Output/2022-08-02/aymeric_dense_T=0.5(2)',\n",
       " 'embeddings_save_path': '/neurospin/dico/agaudin/Runs/04_pointnet/Output/2022-08-02/aymeric_dense_T=0.5(2)/cingulate_ACCpatterns_embeddings',\n",
       " 'pca_Xfit': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.npy',\n",
       " 'pca_Xtransform': '/neurospin/dico/data/deep_folding/current/datasets/ACCpatterns/crops/2mm/CINGULATE/mask/Rskeleton.npy',\n",
       " 'n_pca': '30'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/neurospin/dico/agaudin/Runs/04_pointnet/Output/2022-08-04/15-21-29/.hydra/config.yaml\", 'r') as file:    \n",
    "    config = yaml.load(file, Loader=yaml.BaseLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'backbone_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-339492d9b525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform_no_foldlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/neurospin/dico/agaudin/Runs/04_pointnet/2022_jchavas_cingulate_inhibitory_control/contrastive/data/transforms.py\u001b[0m in \u001b[0;36mtransform_no_foldlabel\u001b[0;34m(from_skeleton, config)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_no_foldlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_skeleton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'pointnet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             transforms.Compose([\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'backbone_name'"
     ]
    }
   ],
   "source": [
    "transform_no_foldlabel(True, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('venv_kraken': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "201dab9319ce8ba60d171e892114127881e651f1ca61b0f33d59df54e7864e9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
